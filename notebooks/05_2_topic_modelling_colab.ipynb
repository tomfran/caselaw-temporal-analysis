{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive') \n",
        "# !unzip src.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XJAxEnv1IJ_",
        "outputId": "730353e8-3165-4be4-ff3d-0933e843b35f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HY9gBtcy0pXP"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "from pprint import pprint\n",
        "from collections import defaultdict\n",
        "\n",
        "# from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.experimental import enable_halving_search_cv\n",
        "from sklearn.model_selection import HalvingGridSearchCV\n",
        "from sklearn.decomposition import LatentDirichletAllocation as lda\n",
        "import pickle\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectors_save_path = \"/content/gdrive/MyDrive/nlp/count.npy\"\n",
        "vectorizer_save_path = \"/content/gdrive/MyDrive/nlp/count.pickle\"\n",
        "\n",
        "vectors = np.load(open(vectors_save_path, \"rb\"), allow_pickle=True).item()\n",
        "vectorizer = pickle.load(open(vectorizer_save_path, \"rb\"))\n"
      ],
      "metadata": {
        "id": "vm9yv9vo2YJ6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Vocabulary len: {len(vectorizer.get_feature_names())}\")\n",
        "print(\"Vectors: \", end=\"\")\n",
        "vectors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yqfgg_JW0q3_",
        "outputId": "67bac1d8-5c63-458e-d78d-257ebe0d2ce3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary len: 48480\n",
            "Vectors: "
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<123915x48480 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 35186442 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "search_params = {\n",
        "    'n_components'  : list(range(5, 33, 3))\n",
        "}\n",
        "search_params"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RUBvdJ69Z2D",
        "outputId": "deef0ca4-8f57-436d-c442-409f01aaee01"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'n_components': [5, 8, 11, 14, 17, 20, 23, 26, 29, 32]}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKyt3-6f0pXY",
        "outputId": "d5a349ca-58b5-4948-961a-2f0fad1dd21e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_iterations: 3\n",
            "n_required_iterations: 3\n",
            "n_possible_iterations: 3\n",
            "min_resources_: 13768\n",
            "max_resources_: 123915\n",
            "aggressive_elimination: False\n",
            "factor: 3\n",
            "----------\n",
            "iter: 0\n",
            "n_candidates: 10\n",
            "n_resources: 13768\n",
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
            "----------\n",
            "iter: 1\n",
            "n_candidates: 4\n",
            "n_resources: 41304\n",
            "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
            "----------\n",
            "iter: 2\n",
            "n_candidates: 2\n",
            "n_resources: 123912\n",
            "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HalvingGridSearchCV(cv=3, estimator=LatentDirichletAllocation(), n_jobs=-1,\n",
              "                    param_grid={'n_components': [5, 8, 11, 14, 17, 20, 23, 26,\n",
              "                                                 29, 32]},\n",
              "                    verbose=2)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "topic_model = lda()\n",
        "# model = GridSearchCV(topic_model, param_grid=search_params,  n_jobs=-1, cv=3, verbose=2)\n",
        "model = HalvingGridSearchCV(topic_model, \n",
        "                            param_grid=search_params, \n",
        "                            min_resources=\"exhaust\", \n",
        "                            factor=3, n_jobs=-1, \n",
        "                            cv=3, verbose=2)\n",
        "model.fit(vectors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BINeqr-A0pXb",
        "outputId": "0b42dc43-e934-4245-df6b-7fe4089ecb96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Model's Params:  {'n_components': 14}\n",
            "Best Log Likelihood Score:  -237546477.92098168\n"
          ]
        }
      ],
      "source": [
        "best_lda_model = model.best_estimator_\n",
        "print(\"Best Model's Params: \", model.best_params_)\n",
        "print(\"Best Log Likelihood Score: \", model.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "f-8hvkmr0pXb"
      },
      "outputs": [],
      "source": [
        "pickle.dump(model.best_estimator_, open(\"IAC_exp_seed_minf_10_max_50%.pk\", \"wb\"))"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "05_topic_modelling_colab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}