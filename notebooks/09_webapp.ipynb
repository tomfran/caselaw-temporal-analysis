{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "e2759ede-7016-46c2-882b-396afdb3c507",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import dash\n",
    "import dash_bootstrap_components as dbc\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import plotly.graph_objs as go\n",
    "import pickle\n",
    "import numpy\n",
    "import random\n",
    "\n",
    "from jupyter_dash import JupyterDash\n",
    "from dash import dcc\n",
    "from dash import html\n",
    "from dash import Input, Output, State\n",
    "from plotly import colors as plotly_colors\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from collections import defaultdict\n",
    "from src.dataset import Dataset\n",
    "from src.vectorizers import TokenVectorizer\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "from src.lda_utils import get_word_relevance, get_words_relevance, print_topics\n",
    "from src.word2vec_utils import align_models, order_by_semantic_shift, get_similarity_sequence_consecutive, get_similarity_sequence_base, show_sequence_plot_base, show_sequence_plot_epochs, load_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "431d6afd-b26d-4701-9c52-bf18ac9ee532",
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOTLY_LOGO = \"https://images.plot.ly/logo/new-branding/plotly-logomark.png\"\n",
    "TEMPLATE = 'plotly_white'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88545594-03b7-4226-bca0-815efd929e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distribution(term, word2id, doc_dates, transposed_vectors, dates_frequencies, low_filter=-1, high_filter=9999):\n",
    "    ind = word2id.get(term, -1)\n",
    "    if ind < 0:\n",
    "        return []\n",
    "    docs = [(index, 1) for index, occ in \n",
    "            enumerate(transposed_vectors[ind].toarray()[0]) if occ > 0]\n",
    "    dates = [(doc_dates[index], occ) for index, occ in docs]\n",
    "    freqs = defaultdict(lambda:0)\n",
    "    for year, occ in dates:\n",
    "        freqs[year] += occ\n",
    "            \n",
    "    return sorted([(year, occ/dates_frequencies[year]) \n",
    "                   for year, occ in freqs.items() if low_filter <= year <= high_filter and occ != dates_frequencies[year]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "141d8af0-8393-497c-8815-dc3ca886ddef",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset()\n",
    "docs = dataset.load_dataset(year=None, fields={\"topic\", \"decision_date\", \"court\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a138910f-b60e-4710-8d49-56f1f66080ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\carle\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\base.py:324: UserWarning:\n",
      "\n",
      "Trying to unpickle estimator CountVectorizer from version 0.24.2 when using version 1.0.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectors, vectorizer = TokenVectorizer.load_vectors_vectorizer(method=\"count\")\n",
    "vocab = vectorizer.get_feature_names()\n",
    "word2id = dict((v, idx) for idx, v in enumerate(vocab))\n",
    "id2word = dict((idx, v) for idx, v in enumerate(vocab))\n",
    "\n",
    "vectors_trans = vectors.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "59c3ded1-929f-4c0a-9a4f-fccb2748f188",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"../data/models/test_w2v.model\"\n",
    "w2v_model = Word2Vec.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ff96e994-2feb-4927-ab2d-8da7f1866747",
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals = 10\n",
    "norm_dates = [e['decision_date'] - e['decision_date']%intervals for e in docs]\n",
    "\n",
    "dates_frequencies = defaultdict(lambda:0)\n",
    "\n",
    "for d in norm_dates:\n",
    "    dates_frequencies[d] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "2d778fdd-d8ae-43b7-be45-b9b719973937",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\carle\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\base.py:324: UserWarning:\n",
      "\n",
      "Trying to unpickle estimator LatentDirichletAllocation from version 0.24.2 when using version 1.0.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "\n"
     ]
    }
   ],
   "source": [
    "generic_lda_model = pickle.load(open(\"../data/models/IAC_exp_seed_minf_10_max_50%.pk\", \"rb\"))\n",
    "specific_lda_model = pickle.load(open(\"../data/models/FULL_exp_seed_t_0_2_13_minf_10_max_50%.pk\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "db8e5b57-d286-4c27-b40d-c567e947d6b2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_topic_words(model, topic_id, vectorizer, n_top_words=10, only_interesting=False, interesting_set={}):\n",
    "    vocab = vectorizer.get_feature_names()\n",
    "    topic_words = {}\n",
    "    comp = model.components_[topic_id]\n",
    "    if only_interesting:\n",
    "        word_idx = numpy.argsort(comp)[::-1]\n",
    "        max_rel = comp[word_idx[0]]\n",
    "        words = [el for el in [(vocab[i], comp[i]/max_rel) for i in word_idx] \n",
    "                              if el[0] in interesting_set][:n_top_words]\n",
    "    else: \n",
    "        word_idx = numpy.argsort(comp)[::-1][:n_top_words]\n",
    "        max_rel = comp[word_idx[0]]\n",
    "        words = [(vocab[i], comp[i]/max_rel) for i in word_idx]        \n",
    "    return words\n",
    "\n",
    "def get_wordcloud_graphs_topic_words(wordcloud):\n",
    "    \n",
    "    word_list = []\n",
    "    freq_list = []\n",
    "    fontsize_list = []\n",
    "    position_list = []\n",
    "    orientation_list = []\n",
    "    color_list = []\n",
    "\n",
    "    for (word, freq), fontsize, position, orientation, color in wordcloud.layout_:\n",
    "        word_list.append(word)\n",
    "        freq_list.append(freq)\n",
    "        fontsize_list.append(fontsize)\n",
    "        position_list.append(position)\n",
    "        orientation_list.append(orientation)\n",
    "        color_list.append(color)\n",
    "    \n",
    "     # get the positions\n",
    "    x_arr = []\n",
    "    y_arr = []\n",
    "    for i in position_list:\n",
    "        x_arr.append(i[0])\n",
    "        y_arr.append(i[1])\n",
    "\n",
    "    # get the relative occurence frequencies\n",
    "    new_freq_list = []\n",
    "    for i in freq_list:\n",
    "        new_freq_list.append(i * 80)\n",
    "\n",
    "    trace = go.Scatter(\n",
    "        x=x_arr,\n",
    "        y=y_arr,\n",
    "        textfont=dict(size=new_freq_list, color=color_list),\n",
    "        hoverinfo=\"text\",\n",
    "        textposition=\"top center\",\n",
    "        hovertext=[\"{0} - {1}\".format(w, f) for w, f in zip(word_list, freq_list)],\n",
    "        mode=\"text\",\n",
    "        text=word_list,\n",
    "    )\n",
    "\n",
    "    layout = go.Layout(\n",
    "        {\n",
    "            \"xaxis\": {\n",
    "                \"showgrid\": False,\n",
    "                \"showticklabels\": False,\n",
    "                \"zeroline\": False,\n",
    "                \"automargin\": True,\n",
    "                \"range\": [-100, 250],\n",
    "            },\n",
    "            \"yaxis\": {\n",
    "                \"showgrid\": False,\n",
    "                \"showticklabels\": False,\n",
    "                \"zeroline\": False,\n",
    "                \"automargin\": True,\n",
    "                \"range\": [-100, 450],\n",
    "            },\n",
    "            \"margin\": dict(t=0, b=0, l=0, r=0, pad=0),\n",
    "            \"hovermode\": \"closest\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return {\"data\": [trace], \"layout\": layout}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "63376d84-8807-4e1d-8467-41a6d17eb4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(date, interval=5):\n",
    "    return date - date%interval\n",
    "\n",
    "# count all frequencies of intervals\n",
    "all_freqs = defaultdict(lambda:0)\n",
    "for el in docs:\n",
    "    d = norm(el['decision_date'])\n",
    "    all_freqs[d] += 1\n",
    "\n",
    "# compute topic frequencies normalized by the total of each interval\n",
    "topic_dists = defaultdict(lambda:defaultdict(lambda:0))\n",
    "for el in docs:\n",
    "    d = norm(el['decision_date'])\n",
    "    t = el[\"topic\"]\n",
    "    for i, e in enumerate(t):\n",
    "        topic_dists[i][d] += e/all_freqs[d]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "c196dc7c-51fe-45d1-a239-ac4b8a01412b",
   "metadata": {},
   "outputs": [],
   "source": [
    "courts_all_freqs = defaultdict(lambda:0)\n",
    "for el in docs:\n",
    "    c = el[\"court\"]\n",
    "    courts_all_freqs[c] += 1\n",
    "\n",
    "court_freqs = defaultdict(lambda:[0]*14)\n",
    "\n",
    "for el in docs:\n",
    "    t = el[\"topic\"]\n",
    "    c = el[\"court\"]\n",
    "    for i, e in enumerate(t):\n",
    "        court_freqs[c][i] += e/courts_all_freqs[c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "64f24b0e-dc91-46b7-84f6-c29430a96ede",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: '../data/models/one_year_time_vectors'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-217-2b0637a8b77d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mone_year_models\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_models\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../data/models/one_year_time_vectors\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0malign_models\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mone_year_models\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mten_years_models\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_models\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../data/models/five_year_time_vectors\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0malign_models\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mten_years_models\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Universita\\Magistrale\\secondo semestre\\information retrieval\\project\\legal-texts-information-retrieval\\src\\word2vec_utils.py\u001b[0m in \u001b[0;36mload_models\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     62\u001b[0m     return { get_name(model_name) : Word2Vec.load(model_name) \n\u001b[0;32m     63\u001b[0m             for model_name in [f\"{path}/{el}\" \n\u001b[1;32m---> 64\u001b[1;33m                                for el in sorted(os.listdir(path)) if \"npy\" not in el]}\n\u001b[0m\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msmart_procrustes_align_gensim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_embed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother_embed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwords\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: '../data/models/one_year_time_vectors'"
     ]
    }
   ],
   "source": [
    "one_year_models = load_models(\"../data/models/one_year_time_vectors\")\n",
    "align_models(one_year_models)\n",
    "\n",
    "ten_years_models = load_models(\"../data/models/five_year_time_vectors\")\n",
    "align_models(ten_years_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "id": "c2d82df4-99ae-40da-b686-63d60f73c463",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = JupyterDash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd7f8ac-c277-4278-8efa-7011051604e8",
   "metadata": {},
   "source": [
    "##### Navbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "ce313404-1f79-4469-a94b-db435baff922",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "NAVBAR = dbc.Navbar(\n",
    "    children=[\n",
    "        html.A(\n",
    "            # Use row and col to control vertical alignment of logo / brand\n",
    "            dbc.Row(\n",
    "                [\n",
    "                    dbc.Col(html.Img(src=PLOTLY_LOGO, height=\"30px\")),\n",
    "                    dbc.Col(\n",
    "                        dbc.NavbarBrand(\"Illinois Cases Analysis\", className=\"ml-2\"),\n",
    "                        style={\"marginLeft\": 10}\n",
    "                    ),\n",
    "                ],\n",
    "                align=\"center\",\n",
    "                className=\"g-0\",\n",
    "            ),\n",
    "            href=\"https://github.com/tomfran/legal-texts-information-retrieval\",\n",
    "            style={\"margin\": 10, \"textDecoration\": \"none\"}\n",
    "        )\n",
    "    ],\n",
    "    color=\"dark\",\n",
    "    dark=True,\n",
    "    sticky=\"top\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7419081a-ace4-43f6-9484-76c86312679e",
   "metadata": {},
   "source": [
    "##### Searchbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "fcc0674d-a028-4479-9d1e-e98e3ec2dec6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SEARCH_BOX = dbc.InputGroup(\n",
    "    [\n",
    "        dbc.Button(\"Search\", id=\"search-button\", n_clicks=0),\n",
    "        dbc.Input(id=\"search-input\", placeholder=\"cocaine, drug - gun, weapon\"),\n",
    "    ],\n",
    "    style={\"marginTop\": 20}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12f25ea-74e4-4937-8f86-9e21b9c268a5",
   "metadata": {},
   "source": [
    "Word Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "2dce477f-ed0d-437b-83f7-2a21c2da8ea3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "WORD_DROPDOWN = dcc.Dropdown(id=\"words-drop\", clearable=False, style={\"font-size\": 12})\n",
    "CONTEXT_GRAPH = dcc.Loading(\n",
    "    id=\"loading-similar-context-words\",\n",
    "    children=[dcc.Graph(id=\"similar-context-graph\")],\n",
    "    type=\"default\",\n",
    ")\n",
    "GRAMS_GRAPH = dcc.Loading(\n",
    "    id=\"loading-grams\", \n",
    "    children=[dcc.Graph(id=\"grams-graph\")],\n",
    "    type=\"default\",\n",
    ")\n",
    "SEMANTIC_YEAR_SLIDER = dcc.Slider(\n",
    "    id=\"semantic-year-slider\",\n",
    "    step=1,\n",
    "    tooltip={\"placement\": \"bottom\", \"always_visible\": True},\n",
    ")\n",
    "SEMANTIC_YEARLY_SHIFT_GRAPH = dcc.Loading(\n",
    "    id=\"loading-yearly-semantic\", \n",
    "    children=[dcc.Graph(id=\"semantic-yearly-shift-graph\")],\n",
    "    type=\"default\",\n",
    ")\n",
    "SEMANTIC_YEARLY_FIRST = dcc.Loading(\n",
    "    id=\"loading-semantic-yearly-first\",\n",
    "    children=[dcc.Graph(id=\"semantic-yearly-first-graph\")],\n",
    "    type=\"default\",\n",
    ")\n",
    "SEMANTIC_YEARLY_SECOND = dcc.Loading(\n",
    "    id=\"loading-semantic-yearly-second\",\n",
    "    children=[dcc.Graph(id=\"semantic-yearly-second-graph\")],\n",
    "    type=\"default\",\n",
    ")\n",
    "\n",
    "SEMANTIC_EPOCH_SHIFT_GRAPH = dcc.Loading(\n",
    "    id=\"loading-epoch-semantic\", \n",
    "    children=[dcc.Graph(id=\"semantic-epoch-shift-graph\")],\n",
    "    type=\"default\",\n",
    ")\n",
    "SEMANTIC_EPOCH_FIRST = dcc.Loading(\n",
    "    id=\"loading-semantic-epoch-first\",\n",
    "    children=[dcc.Graph(id=\"semantic-epoch-first-graph\")],\n",
    "    type=\"default\",\n",
    ")\n",
    "SEMANTIC_EPOCH_SECOND = dcc.Loading(\n",
    "    id=\"loading-semantic-epoch-second\",\n",
    "    children=[dcc.Graph(id=\"semantic-epoch-second-graph\")],\n",
    "    type=\"default\",\n",
    ")\n",
    "\n",
    "SEMANTIC_SHIFT_TABS = dcc.Tabs(\n",
    "    id=\"word-semantic-shift-tabs\",\n",
    "    value=\"Epoch\",\n",
    "    children=[\n",
    "        dcc.Tab(\n",
    "            label=\"Epoch\",\n",
    "            value='Epoch',\n",
    "            children=[\n",
    "                dbc.Row([dbc.Col(SEMANTIC_EPOCH_SHIFT_GRAPH, md=6), dbc.Col(SEMANTIC_EPOCH_FIRST), dbc.Col(SEMANTIC_EPOCH_SECOND)])\n",
    "            ]\n",
    "        ),\n",
    "        dcc.Tab(\n",
    "            label=\"Yearly\",\n",
    "            value='Yeary',\n",
    "            children=[\n",
    "                SEMANTIC_YEAR_SLIDER,\n",
    "                dbc.Row([dbc.Col(SEMANTIC_YEARLY_SHIFT_GRAPH, md=8), dbc.Col(SEMANTIC_YEARLY_FIRST), dbc.Col(SEMANTIC_YEARLY_SECOND)])\n",
    "            ]\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "WORD_GENERIC_TOPIC_DISTRIBUTION_GRAPH = dcc.Loading(\n",
    "    id=\"loading-word-topics\", \n",
    "    children=[dcc.Graph(id=\"word-topics-graph\")],\n",
    "    type=\"default\",\n",
    ")\n",
    "\n",
    "WORD_TOPIC_TABS = dcc.Tabs(\n",
    "    id=\"word-topics-tabs\",\n",
    "    value=\"Generic\",\n",
    "    children=[\n",
    "        dcc.Tab(\n",
    "            label=\"Generic\",\n",
    "            value='Generic'\n",
    "        ),\n",
    "        dcc.Tab(\n",
    "            label=\"Specific\",\n",
    "            value='Specific'\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "6b88ba04-8260-4401-b674-115cf19ab15b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "WORD_CARD = [\n",
    "    dbc.CardHeader(html.H5(\"Word analysis\")),\n",
    "    dbc.Alert(\n",
    "        \"Not enough data to render these plots, please adjust the filters\",\n",
    "        id=\"no-word-data-alert\",\n",
    "        color=\"warning\",\n",
    "        style={\"display\": \"none\"},\n",
    "    ),\n",
    "    dbc.CardBody(\n",
    "        [\n",
    "            dbc.Row(\n",
    "                [\n",
    "                    dbc.Col([\n",
    "                        WORD_DROPDOWN,\n",
    "                        CONTEXT_GRAPH\n",
    "                    ]),\n",
    "                    dbc.Col([GRAMS_GRAPH], md=8)\n",
    "                ]\n",
    "            ),\n",
    "            SEMANTIC_SHIFT_TABS,\n",
    "            dbc.Row([WORD_TOPIC_TABS, WORD_GENERIC_TOPIC_DISTRIBUTION_GRAPH])\n",
    "        ]\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ca1c33-b973-48de-84ab-1ea1ef9e3cd6",
   "metadata": {
    "tags": []
   },
   "source": [
    "Topic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "c9536e4c-88f7-424f-9329-52c18d83e1f7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TOPIC_WORDS_GRAPHS = dbc.Row(\n",
    "    [\n",
    "        dbc.Col(\n",
    "            dcc.Loading(\n",
    "                id=\"loading-topic-top-words\",\n",
    "                children=[dcc.Graph(id=\"topic-top-words-graph\")],\n",
    "                type=\"default\",\n",
    "            )\n",
    "        ),\n",
    "        dbc.Col(\n",
    "            [\n",
    "                dcc.Tabs(\n",
    "                    id=\"tabs\",\n",
    "                    children=[\n",
    "                        dcc.Tab(\n",
    "                            label=\"Treemap\",\n",
    "                            children=[\n",
    "                                dcc.Loading(\n",
    "                                    id=\"loading-treemap\",\n",
    "                                    children=[dcc.Graph(id=\"topic-treemap\")],\n",
    "                                    type=\"default\",\n",
    "                                )\n",
    "                            ],\n",
    "                        ),\n",
    "                        dcc.Tab(\n",
    "                            label=\"Wordcloud\",\n",
    "                            children=[\n",
    "                                dcc.Loading(\n",
    "                                    id=\"loading-wordcloud\",\n",
    "                                    children=[\n",
    "                                        dcc.Graph(id=\"topic-wordcloud\")\n",
    "                                    ],\n",
    "                                    type=\"default\",\n",
    "                                )\n",
    "                            ],\n",
    "                        ),\n",
    "                    ],\n",
    "                )\n",
    "            ],\n",
    "            md=8,\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "id": "300b10b8-1389-443b-9d32-f796a7ac72e0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TOPIC_INFO_GRAPHS = dbc.Row(\n",
    "    [\n",
    "        dbc.Col(\n",
    "            dcc.Loading(\n",
    "                id=\"loading-topic-years\",\n",
    "                children=[\n",
    "                    dcc.Graph(id=\"topic-years-histogram\")\n",
    "                ],\n",
    "                type=\"default\",\n",
    "            )\n",
    "        ),\n",
    "        dbc.Col(\n",
    "            dcc.Loading(\n",
    "                id=\"loading-topic-courts\",\n",
    "                children=[\n",
    "                    dcc.Graph(id=\"topic-courts-graph\")\n",
    "                ],\n",
    "                type=\"default\",\n",
    "            ),\n",
    "            md=4\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "id": "2d9a4349-949d-4103-aec8-67d0df252eba",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TOPIC_CARD = [\n",
    "    dbc.CardHeader(id=\"topic-header\", children=[html.H5(\"Topic 5 - Driving Incidents\", id=\"selected_topic_name\")]),\n",
    "    dbc.Alert(\n",
    "        \"Not enough data to render these plots, please adjust the filters\",\n",
    "        id=\"no-topic-data-alert\",\n",
    "        color=\"warning\",\n",
    "        style={\"display\": \"none\"},\n",
    "    ),\n",
    "    dbc.CardBody(\n",
    "        [TOPIC_WORDS_GRAPHS, TOPIC_INFO_GRAPHS]\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aae1eb7-e987-42d7-b98b-1e8a84e74bf8",
   "metadata": {},
   "source": [
    "##### Body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "937873e5-8694-4ad1-b60b-56a8ec329a38",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BODY = dbc.Container(\n",
    "    [\n",
    "        SEARCH_BOX,\n",
    "        dbc.Card(WORD_CARD, style={\"marginTop\": 20}),\n",
    "        dbc.Card(TOPIC_CARD, style={\"marginTop\": 20, \"marginBottom\": 30}),\n",
    "    ],\n",
    "    className=\"mt-12\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa329d50-731a-43c2-940a-9a5625ada3bb",
   "metadata": {},
   "source": [
    "##### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "5135a360-c977-4592-8e93-398fb2b46f54",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@app.callback(\n",
    "    [\n",
    "        Output(\"words-drop\", \"options\"),\n",
    "        Output(\"words-drop\", \"value\"),\n",
    "    ],\n",
    "    Input('search-button', 'n_clicks'),\n",
    "    State('search-input', 'value')\n",
    ")\n",
    "def populate_bank_dropdown(n_clicks, searches):\n",
    "    if not searches:\n",
    "        return [], None\n",
    "    options = []\n",
    "    for search in searches.split(\"-\"):\n",
    "        search.strip()\n",
    "        options.append({\"label\": search, \"value\": search})\n",
    "    return options, options[0]['value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "id": "4b04fdc3-c398-493d-bb1d-ea2f157e1663",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@app.callback(\n",
    "    Output(\"similar-context-graph\", \"figure\"),\n",
    "    Input(\"words-drop\", \"value\")\n",
    ")\n",
    "def get_similar_context_graph(word):\n",
    "    if not word:\n",
    "        return {}\n",
    "    word = word.strip()\n",
    "    sim = w2v_model.wv.most_similar(word, topn=15)[::-1]\n",
    "    return px.histogram(\n",
    "        y=[word[0] for word in sim],\n",
    "        x=[word[1] for word in sim],\n",
    "        orientation=\"h\",     \n",
    "        title=\"Similar context\",\n",
    "        color_discrete_sequence=['darkturquoise']\n",
    "    ).update_layout(\n",
    "        template=TEMPLATE,\n",
    "        xaxis_title='',\n",
    "        yaxis_title=''\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "174a1b73-eb83-4459-b232-6b14b4679d93",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@app.callback(\n",
    "    Output('semantic-yearly-shift-graph', 'figure'),\n",
    "    [\n",
    "        Input('search-button', 'n_clicks'),\n",
    "        Input(\"semantic-year-slider\", \"value\")\n",
    "    ],\n",
    "    [State('search-input', 'value')])\n",
    "def update_output(n_clicks, year, searches):\n",
    "    if not searches:\n",
    "        return {}\n",
    "    \n",
    "    searches = searches.split(\"-\")\n",
    "    fig = go.Figure(layout=go.Layout(\n",
    "        title=\"Semantic shift - yearly\",\n",
    "        template=TEMPLATE,\n",
    "        xaxis=dict(\n",
    "            rangeselector=dict(\n",
    "                buttons=list([\n",
    "                    dict(count=1,\n",
    "                         label=\"1y\",\n",
    "                         step=\"year\",\n",
    "                         stepmode=\"backward\"),\n",
    "                    dict(count=5,\n",
    "                         label=\"5y\",\n",
    "                         step=\"year\",\n",
    "                         stepmode=\"backward\"),\n",
    "                    dict(count=10,\n",
    "                         label=\"10y\",\n",
    "                         step=\"year\",\n",
    "                         stepmode=\"backward\"),\n",
    "                    dict(count=25,\n",
    "                         label=\"25y\",\n",
    "                         step=\"year\",\n",
    "                         stepmode=\"backward\"),\n",
    "                    dict(count=50,\n",
    "                         label=\"50y\",\n",
    "                         step=\"year\",\n",
    "                         stepmode=\"backward\"),\n",
    "                    dict(step=\"all\")\n",
    "                ])\n",
    "            ),\n",
    "            rangeslider=dict(\n",
    "                visible=True\n",
    "            ),\n",
    "            title=\"year\",\n",
    "            type=\"date\"\n",
    "        ),\n",
    "        yaxis=dict(title=\"freq\")\n",
    "    ))\n",
    "    for search in searches:\n",
    "        search = search.strip()\n",
    "        semantic_shift = get_semantic_shift(search, year)\n",
    "        if not semantic_shift:\n",
    "            continue\n",
    "        fig.add_trace(go.Scatter(x=[year_perc[0] for year_perc in semantic_shift], y=[year_perc[1] for year_perc in semantic_shift],\n",
    "                            mode='lines',\n",
    "                            name=search))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "5b4b8316-ae52-408d-b948-3dc9fc0028b9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@app.callback(\n",
    "    [\n",
    "        Output('semantic-epoch-shift-graph', 'figure'),\n",
    "        Output(\"semantic-year-slider\", \"marks\"),\n",
    "        Output(\"semantic-year-slider\", \"min\"),\n",
    "        Output(\"semantic-year-slider\", \"max\"),\n",
    "        Output(\"semantic-year-slider\", \"value\"),\n",
    "    ],\n",
    "    [Input('search-button', 'n_clicks')],\n",
    "    [State('search-input', 'value')])\n",
    "def update_output(n_clicks, searches):\n",
    "    if not searches:\n",
    "        return {}, {}, 0, 0, 0\n",
    "    \n",
    "    searches = searches.split(\"-\")\n",
    "    fig = go.Figure(layout=go.Layout(\n",
    "        title=\"Semantic shift - epoch\",\n",
    "        template=TEMPLATE,\n",
    "        xaxis=dict(\n",
    "            rangeselector=dict(\n",
    "                buttons=list([\n",
    "                    dict(count=1,\n",
    "                         label=\"1y\",\n",
    "                         step=\"year\",\n",
    "                         stepmode=\"backward\"),\n",
    "                    dict(count=5,\n",
    "                         label=\"5y\",\n",
    "                         step=\"year\",\n",
    "                         stepmode=\"backward\"),\n",
    "                    dict(count=10,\n",
    "                         label=\"10y\",\n",
    "                         step=\"year\",\n",
    "                         stepmode=\"backward\"),\n",
    "                    dict(count=25,\n",
    "                         label=\"25y\",\n",
    "                         step=\"year\",\n",
    "                         stepmode=\"backward\"),\n",
    "                    dict(count=50,\n",
    "                         label=\"50y\",\n",
    "                         step=\"year\",\n",
    "                         stepmode=\"backward\"),\n",
    "                    dict(step=\"all\")\n",
    "                ])\n",
    "            ),\n",
    "            rangeslider=dict(\n",
    "                visible=True\n",
    "            ),\n",
    "            title=\"year\",\n",
    "            type=\"date\"\n",
    "        ),\n",
    "        yaxis=dict(title=\"freq\")\n",
    "    ))\n",
    "    for search in searches:\n",
    "        search = search.strip()\n",
    "        semantic_shift = get_semantic_shift(search)\n",
    "        if not semantic_shift:\n",
    "            continue\n",
    "        \n",
    "        min_year, max_year = semantic_shift[0][0], semantic_shift[-1][0]\n",
    "            \n",
    "        fig.add_trace(go.Scatter(x=[year_perc[0] for year_perc in semantic_shift], y=[year_perc[1] for year_perc in semantic_shift],\n",
    "                            mode='lines',\n",
    "                            name=search))\n",
    "    return fig, {min_year: f\"{min_year}\", max_year: f\"{max_year}\"}, min_year, max_year, max_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "id": "71af87ec-70ea-4b9e-8869-849f7b1f7d0a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@app.callback(\n",
    "    Output(\"word-topics-graph\", \"figure\"),\n",
    "    [\n",
    "        Input('search-button', 'n_clicks'),\n",
    "        Input('word-topics-tabs', 'value')\n",
    "    ],\n",
    "    State('search-input', 'value'))\n",
    "def get_generic_topics_radar_graph(n_clicks, tab, searches):\n",
    "    if not searches:\n",
    "        return {}\n",
    "\n",
    "    fig = go.Figure(layout=go.Layout(\n",
    "            title=\"Topic distribution\",\n",
    "            template=TEMPLATE,\n",
    "    )               )\n",
    "    \n",
    "    searches = searches.split(\"-\")\n",
    "    for search in searches:\n",
    "        search = search.strip()\n",
    "        \n",
    "        topics = get_word_relevance(search, word2id, vocab, generic_lda_model if tab == \"Generic\" else specific_lda_model, normalize=True)\n",
    "        values = numpy.array(list(topics.values()), dtype='f') * 100 / max(topics.values())\n",
    "        \n",
    "        fig.add_trace(go.Scatterpolar(\n",
    "            r=values,\n",
    "            theta=[str(name) for name in list(topics.keys())],\n",
    "            fill='toself',\n",
    "            name=search,\n",
    "            hoverinfo=\"text\",\n",
    "            textposition=\"top center\",       \n",
    "            hovertext=[f\"Topic {format(value, '.2f')}%\" for topic, value in zip(topics, values)]\n",
    "        ))\n",
    "\n",
    "    fig.update_layout(\n",
    "      polar=dict(\n",
    "        radialaxis=dict(\n",
    "          visible=False,\n",
    "          range=[0, 100]\n",
    "        )),\n",
    "      showlegend=True\n",
    "    )\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "id": "62b3db48-80bc-4b34-b4d6-879a11f2c89e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@app.callback(\n",
    "    [\n",
    "        Output(\"topic-header\", \"children\"),\n",
    "        Output(\"topic-top-words-graph\", \"figure\"),\n",
    "        Output(\"topic-treemap\", \"figure\"),\n",
    "        Output(\"topic-wordcloud\", \"figure\")\n",
    "    ],\n",
    "    [\n",
    "        Input('word-topics-graph', 'clickData'),\n",
    "        Input('word-topics-tabs', 'value')\n",
    "    ],)\n",
    "def get_topic_words_radar_graph(selected_topic, tab):\n",
    "    if not selected_topic:\n",
    "        return [html.H5(\"Select a topic\")], {}, {}, {}\n",
    "    topic_id = selected_topic['points'][0]['pointNumber']\n",
    "    sim = get_topic_words(generic_lda_model if tab == \"Generic\" else specific_lda_model, \n",
    "                          topic_id,\n",
    "                          vectorizer, \n",
    "                          n_top_words=80, \n",
    "                          only_interesting=False)\n",
    "    \n",
    "    words = [word[0] for word in sim]\n",
    "    freqs = [word[1] for word in sim]\n",
    "    \n",
    "    treemap_trace = go.Treemap(\n",
    "        labels=words[:40], parents=[\"\"] * len(words[:40]), values=freqs\n",
    "    )\n",
    "    treemap_layout = go.Layout({\"margin\": dict(t=0, b=0, l=0, r=0, pad=0)})\n",
    "    treemap_figure = {\"data\": [treemap_trace], \"layout\": treemap_layout}\n",
    "    \n",
    "    wc = WordCloud().generate_from_frequencies(frequencies={word[0]: word[1] for word in sim})\n",
    "    wordcloud = get_wordcloud_graphs_topic_words(wc)\n",
    "    \n",
    "    return [html.H5(f\"{tab} Topic {topic_id}\")],px.histogram(\n",
    "        y=words[:20][::-1],\n",
    "        x=freqs[:20][::-1],\n",
    "        orientation=\"h\",     \n",
    "        color_discrete_sequence=['darkturquoise']\n",
    "    ).update_layout(\n",
    "        template=TEMPLATE,\n",
    "        xaxis_title='',\n",
    "        yaxis_title='',\n",
    "        height=550\n",
    "    ), treemap_figure, wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "id": "f8f58dd2-8fd8-4678-87fa-a7e1d3ac87b3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@app.callback(\n",
    "    Output(\"topic-years-histogram\", \"figure\"),\n",
    "    [\n",
    "        Input('word-topics-graph', 'clickData'),\n",
    "        Input('word-topics-tabs', 'value')\n",
    "    ],)\n",
    "def get_topic_years_histogram(selected_topic, tab):\n",
    "    if not selected_topic:\n",
    "        return {}\n",
    "    topic_id = selected_topic['points'][0]['pointNumber']\n",
    "    data = [\n",
    "        {\n",
    "            \"x\": list(topic_dists[topic_id].keys()),\n",
    "            \"y\": list(topic_dists[topic_id].values()),\n",
    "            \"text\": list(topic_dists[topic_id].keys()),\n",
    "            \"type\": \"bar\",\n",
    "            \"name\": \"\",\n",
    "        }\n",
    "    ]\n",
    "    layout = {\n",
    "        \"autosize\": True,\n",
    "        \"margin\": dict(t=10, b=20, l=40, r=0, pad=4),\n",
    "        \"xaxis\": dict(rangeselector=dict(\n",
    "            buttons=list([\n",
    "                dict(count=1,\n",
    "                     label=\"1y\",\n",
    "                     step=\"year\",\n",
    "                     stepmode=\"backward\"),\n",
    "                dict(count=5,\n",
    "                     label=\"5y\",\n",
    "                     step=\"year\",\n",
    "                     stepmode=\"backward\"),\n",
    "                dict(count=10,\n",
    "                     label=\"10y\",\n",
    "                     step=\"year\",\n",
    "                     stepmode=\"backward\"),\n",
    "                dict(count=25,\n",
    "                     label=\"25y\",\n",
    "                     step=\"year\",\n",
    "                     stepmode=\"backward\"),\n",
    "                dict(count=50,\n",
    "                     label=\"50y\",\n",
    "                     step=\"year\",\n",
    "                     stepmode=\"backward\"),\n",
    "                dict(step=\"all\")\n",
    "            ])\n",
    "        ),\n",
    "                       rangeslider=dict(\n",
    "                            visible=True\n",
    "                        ),\n",
    "                       title=\"year\",\n",
    "                       type=\"date\",\n",
    "                       showticklabels=True, )\n",
    "    }\n",
    "    return {\"data\": data, \"layout\": layout}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "id": "d7acd45a-2b63-4587-a90b-e2f0851abfdd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@app.callback(\n",
    "    Output(\"topic-courts-graph\", \"figure\"),\n",
    "    [\n",
    "        Input('word-topics-graph', 'clickData'),\n",
    "        Input('word-topics-tabs', 'value')\n",
    "    ],)\n",
    "def get_topic_courts_distribution_radar_graph(selected_topic, tab):\n",
    "    if not selected_topic:\n",
    "        return {}\n",
    "\n",
    "    topic_id = selected_topic['points'][0]['pointNumber']\n",
    "    \n",
    "    fig = go.Figure(layout=go.Layout(\n",
    "            title=\"Courts distribution\",\n",
    "            template=TEMPLATE,\n",
    "    )               )\n",
    "    \n",
    "    values = [topics[topic_id] * 100 for topics in court_freqs.values()]\n",
    "    max_value = max(values)\n",
    "        \n",
    "    fig.add_trace(go.Scatterpolar(\n",
    "        r=values,\n",
    "        theta=[court.split(\"Illinois\")[1].strip() for court in list(court_freqs.keys())],\n",
    "        fill='toself',\n",
    "        name=str(topic_id),\n",
    "        hoverinfo=\"text\",\n",
    "        textposition=\"top center\",       \n",
    "        hovertext=[f\"{round(value, 2)}%\" for value in values],\n",
    "    ))\n",
    "\n",
    "    fig.update_layout(\n",
    "      polar=dict(\n",
    "        radialaxis=dict(\n",
    "          visible=False,\n",
    "          range=[0, int(max_value * 1.5) if max_value < 50 else int(max_value + 10)]\n",
    "        )\n",
    "      )\n",
    "    )\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "id": "b2bb0f13-8ccc-4254-912c-559081773afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "app.layout = html.Div(children=[NAVBAR, BODY])\n",
    "\n",
    "app.run_server(mode='jupyterlab', dev_tools_ui=True, #debug=True, \n",
    "               dev_tools_hot_reload =True, threaded=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "id": "911da111-c361-4398-869a-39e59c778834",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _terminate_server_for_port(host, port):\n",
    "        shutdown_url = \"http://{host}:{port}/_shutdown_{token}\".format(\n",
    "            host=host, port=port, token=JupyterDash._token\n",
    "        )\n",
    "        try:\n",
    "            response = requests.get(shutdown_url)\n",
    "        except Exception as e:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "5369e70b-ee4d-4d35-9ecd-e9b92b87091e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _terminate_server_for_port(\"localhost\", 8050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06185d4-9988-4d37-9257-b955de8f1f3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0142df49-aeb3-4da5-bb3e-2c9cc12273af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc5012d-1593-4b10-8fc8-92c262743302",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
