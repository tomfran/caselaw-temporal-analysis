{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset preprocessing\n",
    "Data is loaded with the Dataset class, we first partition data over intervals of twenty years, we consider relevant information from entry and we merge opinions into a big text, with some preprocessing such as removing punctuation, symbols, numbers, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import json\n",
    "from pprint import pprint\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.dpi'] = 90\n",
    "\n",
    "from src.dataset import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(dataset_path=\"../data/raw/data.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving documents from 1760 to 1779\n",
      "Saving documents from 1800 to 1819\n",
      "Saving documents from 1820 to 1839\n",
      "Saving documents from 1840 to 1859\n",
      "Saving documents from 1860 to 1879\n",
      "Saving documents from 1880 to 1899\n",
      "Saving documents from 1900 to 1919\n",
      "Saving documents from 1920 to 1939\n",
      "Saving documents from 1940 to 1959\n",
      "Saving documents from 1960 to 1979\n",
      "Saving documents from 1980 to 1999\n",
      "Saving documents from 2000 to 2019\n"
     ]
    }
   ],
   "source": [
    "dataset.partition_save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge data with tokens and topics\n",
    "This cell is runned after later notebooks, in particular after the second one and the 05_4 one, as we find tokens and topics for each document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1760.json\n",
      "Processing 1800.json\n",
      "Processing 1820.json\n",
      "Processing 1840.json\n",
      "Processing 1860.json\n",
      "Processing 1880.json\n",
      "Processing 1900.json\n",
      "Processing 1920.json\n",
      "Processing 1940.json\n",
      "Processing 1960.json\n",
      "Processing 1980.json\n",
      "Processing 2000.json\n"
     ]
    }
   ],
   "source": [
    "dataset.merge_tokens_topics_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset distributions study\n",
    "Datapoint example and distribution studies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset.load_dataset(year=None)\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "courts_counts = defaultdict(lambda:0)\n",
    "years_count = defaultdict(lambda:0)\n",
    "\n",
    "for doc in data:\n",
    "    courts_counts[doc[\"court\"]] += 1\n",
    "    years_count[doc[\"decision_date\"]//10*10] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = list(courts_counts.keys()), list(courts_counts.values())\n",
    "plt.bar(x, y)\n",
    "plt.title(\"Courts distribution\")\n",
    "plt.xlabel(\"Courts\")\n",
    "plt.ylabel(\"Num. documents\")\n",
    "for i, v in enumerate(y):\n",
    "    plt.text(i-0.1, v+1000, v)\n",
    "plt.xticks(x, rotation='vertical')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = list(years_count.keys()), list(years_count.values())\n",
    "plt.bar(x, y, width=5)\n",
    "plt.title(\"Years distribution\")\n",
    "plt.xlabel(\"Years\")\n",
    "plt.ylabel(\"Num. documents\")\n",
    "plt.xticks(x, rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_years_count = defaultdict(lambda:0)\n",
    "\n",
    "for doc in data:\n",
    "    if doc[\"court\"] == \"Illinois Appellate Court\":\n",
    "        app_years_count[doc[\"decision_date\"]//10*10] += 1\n",
    "\n",
    "x, y = list(app_years_count.keys()), list(app_years_count.values())\n",
    "plt.bar(x, y, width=5)\n",
    "plt.title(\"Illinois Appellate Court years distribution\")\n",
    "plt.xlabel(\"Years\")\n",
    "plt.ylabel(\"Num. documents\")\n",
    "plt.xticks(x, rotation='vertical')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
