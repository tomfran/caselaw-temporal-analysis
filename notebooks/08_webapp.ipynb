{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "e2759ede-7016-46c2-882b-396afdb3c507",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import dash\n",
    "import dash_bootstrap_components as dbc\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import plotly.graph_objs as go\n",
    "import pickle\n",
    "import numpy\n",
    "import random\n",
    "\n",
    "from jupyter_dash import JupyterDash\n",
    "from dash import dcc\n",
    "from dash import html\n",
    "from dash import Input, Output, State\n",
    "from plotly import colors as plotly_colors\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from collections import defaultdict\n",
    "from src.dataset import Dataset\n",
    "from src.vectorizers import TokenVectorizer\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "from src.lda_utils import get_word_relevance, get_words_relevance, print_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "431d6afd-b26d-4701-9c52-bf18ac9ee532",
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOTLY_LOGO = \"https://images.plot.ly/logo/new-branding/plotly-logomark.png\"\n",
    "TEMPLATE = 'plotly_white'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "88545594-03b7-4226-bca0-815efd929e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distribution(term, word2id, doc_dates, transposed_vectors, dates_frequencies, low_filter=-1, high_filter=9999):\n",
    "    ind = word2id.get(term, -1)\n",
    "    if ind < 0:\n",
    "        return []\n",
    "    docs = [(index, 1) for index, occ in \n",
    "            enumerate(transposed_vectors[ind].toarray()[0]) if occ > 0]\n",
    "    dates = [(doc_dates[index], occ) for index, occ in docs]\n",
    "    freqs = defaultdict(lambda:0)\n",
    "    for year, occ in dates:\n",
    "        freqs[year] += occ\n",
    "            \n",
    "    return sorted([(year, occ/dates_frequencies[year]) \n",
    "                   for year, occ in freqs.items() if low_filter <= year <= high_filter and occ != dates_frequencies[year]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "141d8af0-8393-497c-8815-dc3ca886ddef",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-237-c95bc17a310e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myear\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfields\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"topic\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"decision_date\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcourts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"Illinois Appellate Court\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Desktop\\Universita\\Magistrale\\secondo semestre\\information retrieval\\project\\legal-texts-information-retrieval\\src\\dataset.py\u001b[0m in \u001b[0;36mload_dataset\u001b[1;34m(self, year, fields, courts)\u001b[0m\n\u001b[0;32m     97\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfile_names\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcourts\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Universita\\Magistrale\\secondo semestre\\information retrieval\\project\\legal-texts-information-retrieval\\src\\dataset.py\u001b[0m in \u001b[0;36mload_json\u001b[1;34m(self, path)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mload_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_filter_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfields\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\carle\\appdata\\local\\programs\\python\\python39\\lib\\json\\__init__.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    291\u001b[0m     \u001b[0mkwarg\u001b[0m\u001b[1;33m;\u001b[0m \u001b[0motherwise\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mJSONDecoder\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mused\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m     \"\"\"\n\u001b[1;32m--> 293\u001b[1;33m     return loads(fp.read(),\n\u001b[0m\u001b[0;32m    294\u001b[0m         \u001b[0mcls\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobject_hook\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobject_hook\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m         \u001b[0mparse_float\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparse_float\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparse_int\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparse_int\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\carle\\appdata\\local\\programs\\python\\python39\\lib\\json\\__init__.py\u001b[0m in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    344\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[1;32m--> 346\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    347\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m         \u001b[0mcls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\carle\\appdata\\local\\programs\\python\\python39\\lib\\json\\decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    335\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m         \"\"\"\n\u001b[1;32m--> 337\u001b[1;33m         \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\carle\\appdata\\local\\programs\\python\\python39\\lib\\json\\decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    351\u001b[0m         \"\"\"\n\u001b[0;32m    352\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 353\u001b[1;33m             \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    354\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Expecting value\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataset = Dataset()\n",
    "dates = dataset.load_dataset(year=None, fields={\"topic\", \"decision_date\"}, courts={\"Illinois Appellate Court\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a138910f-b60e-4710-8d49-56f1f66080ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\carle\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\base.py:324: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.24.2 when using version 1.0.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\users\\carle\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "vectors, vectorizer = TokenVectorizer.load_vectors_vectorizer(method=\"count\")\n",
    "vocab = vectorizer.get_feature_names()\n",
    "word2id = dict((v, idx) for idx, v in enumerate(vocab))\n",
    "id2word = dict((idx, v) for idx, v in enumerate(vocab))\n",
    "\n",
    "vectors_trans = vectors.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59c3ded1-929f-4c0a-9a4f-fccb2748f188",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"../data/models/test_w2v.model\"\n",
    "w2v_model = Word2Vec.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff96e994-2feb-4927-ab2d-8da7f1866747",
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals = 10\n",
    "norm_dates = [e['decision_date'] - e['decision_date']%intervals for e in dates]\n",
    "\n",
    "dates_frequencies = defaultdict(lambda:0)\n",
    "\n",
    "for d in norm_dates:\n",
    "    dates_frequencies[d] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d778fdd-d8ae-43b7-be45-b9b719973937",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\carle\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\base.py:324: UserWarning: Trying to unpickle estimator LatentDirichletAllocation from version 0.24.2 when using version 1.0.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "generic_lda_model = pickle.load(open(\"../data/models/IAC_exp_seed_minf_10_max_50%.pk\", \"rb\"))\n",
    "specific_lda_model = pickle.load(open(\"../data/models/FULL_exp_seed_t_0_2_13_minf_10_max_50%.pk\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "id": "db8e5b57-d286-4c27-b40d-c567e947d6b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_topic_words(model, topic_id, vectorizer, n_top_words=10, only_interesting=False, interesting_set={}):\n",
    "    vocab = vectorizer.get_feature_names()\n",
    "    topic_words = {}\n",
    "    comp = model.components_[topic_id]\n",
    "    if only_interesting:\n",
    "        word_idx = numpy.argsort(comp)[::-1]\n",
    "        max_rel = comp[word_idx[0]]\n",
    "        words = [el for el in [(vocab[i], comp[i]/max_rel) for i in word_idx] \n",
    "                              if el[0] in interesting_set][:n_top_words]\n",
    "    else: \n",
    "        word_idx = numpy.argsort(comp)[::-1][:n_top_words]\n",
    "        max_rel = comp[word_idx[0]]\n",
    "        words = [(vocab[i], comp[i]/max_rel) for i in word_idx]        \n",
    "    return words\n",
    "\n",
    "def get_wordcloud_graphs_topic_words(wordcloud):\n",
    "    \n",
    "    word_list = []\n",
    "    freq_list = []\n",
    "    fontsize_list = []\n",
    "    position_list = []\n",
    "    orientation_list = []\n",
    "    color_list = []\n",
    "\n",
    "    for (word, freq), fontsize, position, orientation, color in wordcloud.layout_:\n",
    "        word_list.append(word)\n",
    "        freq_list.append(freq)\n",
    "        fontsize_list.append(fontsize)\n",
    "        position_list.append(position)\n",
    "        orientation_list.append(orientation)\n",
    "        color_list.append(color)\n",
    "    \n",
    "     # get the positions\n",
    "    x_arr = []\n",
    "    y_arr = []\n",
    "    for i in position_list:\n",
    "        x_arr.append(i[0])\n",
    "        y_arr.append(i[1])\n",
    "\n",
    "    # get the relative occurence frequencies\n",
    "    new_freq_list = []\n",
    "    for i in freq_list:\n",
    "        new_freq_list.append(i * 80)\n",
    "\n",
    "    trace = go.Scatter(\n",
    "        x=x_arr,\n",
    "        y=y_arr,\n",
    "        textfont=dict(size=new_freq_list, color=color_list),\n",
    "        hoverinfo=\"text\",\n",
    "        textposition=\"top center\",\n",
    "        hovertext=[\"{0} - {1}\".format(w, f) for w, f in zip(word_list, freq_list)],\n",
    "        mode=\"text\",\n",
    "        text=word_list,\n",
    "    )\n",
    "\n",
    "    layout = go.Layout(\n",
    "        {\n",
    "            \"xaxis\": {\n",
    "                \"showgrid\": False,\n",
    "                \"showticklabels\": False,\n",
    "                \"zeroline\": False,\n",
    "                \"automargin\": True,\n",
    "                \"range\": [-100, 250],\n",
    "            },\n",
    "            \"yaxis\": {\n",
    "                \"showgrid\": False,\n",
    "                \"showticklabels\": False,\n",
    "                \"zeroline\": False,\n",
    "                \"automargin\": True,\n",
    "                \"range\": [-100, 450],\n",
    "            },\n",
    "            \"margin\": dict(t=0, b=0, l=0, r=0, pad=0),\n",
    "            \"hovermode\": \"closest\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return {\"data\": [trace], \"layout\": layout}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63376d84-8807-4e1d-8467-41a6d17eb4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(date, interval=5):\n",
    "    return date - date%interval\n",
    "\n",
    "# count all frequencies of intervals\n",
    "all_freqs = defaultdict(lambda:0)\n",
    "for el in dates:\n",
    "    d = norm(el['decision_date'])\n",
    "    all_freqs[d] += 1\n",
    "\n",
    "# compute topic frequencies normalized by the total of each interval\n",
    "topic_dists = defaultdict(lambda:defaultdict(lambda:0))\n",
    "for el in dates:\n",
    "    d = norm(el['decision_date'])\n",
    "    t = el[\"topic\"]\n",
    "    for i, e in enumerate(t):\n",
    "        topic_dists[i][d] += e/all_freqs[d]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "id": "c2d82df4-99ae-40da-b686-63d60f73c463",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = JupyterDash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd7f8ac-c277-4278-8efa-7011051604e8",
   "metadata": {},
   "source": [
    "##### Navbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "id": "ce313404-1f79-4469-a94b-db435baff922",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "NAVBAR = dbc.Navbar(\n",
    "    children=[\n",
    "        html.A(\n",
    "            # Use row and col to control vertical alignment of logo / brand\n",
    "            dbc.Row(\n",
    "                [\n",
    "                    dbc.Col(html.Img(src=PLOTLY_LOGO, height=\"30px\")),\n",
    "                    dbc.Col(\n",
    "                        dbc.NavbarBrand(\"Illinois Cases Analysis\", className=\"ml-2\"),\n",
    "                        style={\"marginLeft\": 10}\n",
    "                    ),\n",
    "                ],\n",
    "                align=\"center\",\n",
    "                className=\"g-0\",\n",
    "            ),\n",
    "            href=\"https://github.com/tomfran/legal-texts-information-retrieval\",\n",
    "            style={\"margin\": 10, \"textDecoration\": \"none\"}\n",
    "        )\n",
    "    ],\n",
    "    color=\"dark\",\n",
    "    dark=True,\n",
    "    sticky=\"top\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7419081a-ace4-43f6-9484-76c86312679e",
   "metadata": {},
   "source": [
    "##### Searchbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "id": "fcc0674d-a028-4479-9d1e-e98e3ec2dec6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SEARCH_BOX = dbc.InputGroup(\n",
    "    [\n",
    "        dbc.Button(\"Search\", id=\"search-button\", n_clicks=0),\n",
    "        dbc.Input(id=\"search-input\", placeholder=\"cocaine, drug - gun, weapon\"),\n",
    "    ],\n",
    "    style={\"marginTop\": 20}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12f25ea-74e4-4937-8f86-9e21b9c268a5",
   "metadata": {},
   "source": [
    "Word Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "id": "2dce477f-ed0d-437b-83f7-2a21c2da8ea3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "WORD_DROPDOWN = dcc.Dropdown(id=\"words-drop\", clearable=False, style={\"font-size\": 12})\n",
    "CONTEXT_GRAPH = dcc.Loading(\n",
    "    id=\"loading-similar-context-words\",\n",
    "    children=[dcc.Graph(id=\"similar-context-graph\")],\n",
    "    type=\"default\",\n",
    ")\n",
    "GRAMS_GRAPH = dcc.Loading(\n",
    "    id=\"loading-grams\", \n",
    "    children=[dcc.Graph(id=\"grams-graph\")],\n",
    "    type=\"default\",\n",
    ")\n",
    "WORD_GENERIC_TOPIC_DISTRIBUTION_GRAPH = dcc.Loading(\n",
    "    id=\"loading-word-topics\", \n",
    "    children=[dcc.Graph(id=\"word-topics-graph\")],\n",
    "    type=\"default\",\n",
    ")\n",
    "\n",
    "WORD_TOPIC_TABS = dcc.Tabs(\n",
    "    id=\"word-topics-tabs\",\n",
    "    value=\"Generic\",\n",
    "    children=[\n",
    "        dcc.Tab(\n",
    "            label=\"Generic\",\n",
    "            value='Generic'\n",
    "        ),\n",
    "        dcc.Tab(\n",
    "            label=\"Specific\",\n",
    "            value='Specific'\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "id": "6b88ba04-8260-4401-b674-115cf19ab15b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "WORD_CARD = [\n",
    "    dbc.CardHeader(html.H5(\"Word analysis\")),\n",
    "    dbc.Alert(\n",
    "        \"Not enough data to render these plots, please adjust the filters\",\n",
    "        id=\"no-word-data-alert\",\n",
    "        color=\"warning\",\n",
    "        style={\"display\": \"none\"},\n",
    "    ),\n",
    "    dbc.CardBody(\n",
    "        [\n",
    "            dbc.Row(\n",
    "                [\n",
    "                    dbc.Col([\n",
    "                        WORD_DROPDOWN,\n",
    "                        CONTEXT_GRAPH\n",
    "                    ]),\n",
    "                    dbc.Col([GRAMS_GRAPH], md=8)\n",
    "                ]\n",
    "            ),\n",
    "            dbc.Row([WORD_TOPIC_TABS, WORD_GENERIC_TOPIC_DISTRIBUTION_GRAPH])\n",
    "        ]\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ca1c33-b973-48de-84ab-1ea1ef9e3cd6",
   "metadata": {},
   "source": [
    "Topic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "id": "c9536e4c-88f7-424f-9329-52c18d83e1f7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TOPIC_WORDS_GRAPHS = dbc.Row(\n",
    "    [\n",
    "        dbc.Col(\n",
    "            dcc.Loading(\n",
    "                id=\"loading-topic-top-words\",\n",
    "                children=[dcc.Graph(id=\"topic-top-words-graph\")],\n",
    "                type=\"default\",\n",
    "            )\n",
    "        ),\n",
    "        dbc.Col(\n",
    "            [\n",
    "                dcc.Tabs(\n",
    "                    id=\"tabs\",\n",
    "                    children=[\n",
    "                        dcc.Tab(\n",
    "                            label=\"Treemap\",\n",
    "                            children=[\n",
    "                                dcc.Loading(\n",
    "                                    id=\"loading-treemap\",\n",
    "                                    children=[dcc.Graph(id=\"topic-treemap\")],\n",
    "                                    type=\"default\",\n",
    "                                )\n",
    "                            ],\n",
    "                        ),\n",
    "                        dcc.Tab(\n",
    "                            label=\"Wordcloud\",\n",
    "                            children=[\n",
    "                                dcc.Loading(\n",
    "                                    id=\"loading-wordcloud\",\n",
    "                                    children=[\n",
    "                                        dcc.Graph(id=\"topic-wordcloud\")\n",
    "                                    ],\n",
    "                                    type=\"default\",\n",
    "                                )\n",
    "                            ],\n",
    "                        ),\n",
    "                    ],\n",
    "                )\n",
    "            ],\n",
    "            md=8,\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "id": "300b10b8-1389-443b-9d32-f796a7ac72e0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TOPIC_INFO_GRAPHS = dbc.Row(\n",
    "    [\n",
    "        dbc.Col(\n",
    "            dcc.Loading(\n",
    "                id=\"loading-topic-years\",\n",
    "                children=[\n",
    "                    dcc.Graph(id=\"topic-years-histogram\")\n",
    "                ],\n",
    "                type=\"default\",\n",
    "            )\n",
    "        ),\n",
    "        dbc.Col(\n",
    "            dcc.Loading(\n",
    "                id=\"loading-topic-courts\",\n",
    "                children=[\n",
    "                    dcc.Graph(id=\"topic-courts-piechart\")\n",
    "                ],\n",
    "                type=\"default\",\n",
    "            ),\n",
    "            md=4\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "id": "2d9a4349-949d-4103-aec8-67d0df252eba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TOPIC_CARD = [\n",
    "    dbc.CardHeader(id=\"topic-header\", children=[html.H5(\"Topic 5 - Driving Incidents\", id=\"selected_topic_name\")]),\n",
    "    dbc.Alert(\n",
    "        \"Not enough data to render these plots, please adjust the filters\",\n",
    "        id=\"no-topic-data-alert\",\n",
    "        color=\"warning\",\n",
    "        style={\"display\": \"none\"},\n",
    "    ),\n",
    "    dbc.CardBody(\n",
    "        [TOPIC_WORDS_GRAPHS, TOPIC_INFO_GRAPHS]\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aae1eb7-e987-42d7-b98b-1e8a84e74bf8",
   "metadata": {},
   "source": [
    "##### Body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "id": "937873e5-8694-4ad1-b60b-56a8ec329a38",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BODY = dbc.Container(\n",
    "    [\n",
    "        SEARCH_BOX,\n",
    "        dbc.Card(WORD_CARD, style={\"marginTop\": 20}),\n",
    "        dbc.Card(TOPIC_CARD, style={\"marginTop\": 20, \"marginBottom\": 30}),\n",
    "    ],\n",
    "    className=\"mt-12\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa329d50-731a-43c2-940a-9a5625ada3bb",
   "metadata": {},
   "source": [
    "##### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "id": "5135a360-c977-4592-8e93-398fb2b46f54",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@app.callback(\n",
    "    [\n",
    "        Output(\"words-drop\", \"options\"),\n",
    "        Output(\"words-drop\", \"value\"),\n",
    "    ],\n",
    "    Input('search-button', 'n_clicks'),\n",
    "    State('search-input', 'value')\n",
    ")\n",
    "def populate_bank_dropdown(n_clicks, searches):\n",
    "    if not searches:\n",
    "        return [], None\n",
    "    options = []\n",
    "    for search in searches.split(\"-\"):\n",
    "        search.strip()\n",
    "        options.append({\"label\": search, \"value\": search})\n",
    "    return options, options[0]['value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "id": "4b04fdc3-c398-493d-bb1d-ea2f157e1663",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@app.callback(\n",
    "    Output(\"similar-context-graph\", \"figure\"),\n",
    "    Input(\"words-drop\", \"value\")\n",
    ")\n",
    "def get_similar_context_graph(word):\n",
    "    if not word:\n",
    "        return {}\n",
    "    word = word.strip()\n",
    "    sim = w2v_model.wv.most_similar(word, topn=15)[::-1]\n",
    "    return px.histogram(\n",
    "        y=[word[0] for word in sim],\n",
    "        x=[word[1] for word in sim],\n",
    "        orientation=\"h\",     \n",
    "        title=\"Similar context\",\n",
    "        color_discrete_sequence=['darkturquoise']\n",
    "    ).update_layout(\n",
    "        template=TEMPLATE,\n",
    "        xaxis_title='',\n",
    "        yaxis_title=''\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "id": "174a1b73-eb83-4459-b232-6b14b4679d93",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@app.callback(\n",
    "    Output('grams-graph', 'figure'),\n",
    "    [Input('search-button', 'n_clicks')],\n",
    "    [State('search-input', 'value')])\n",
    "def update_output(n_clicks, searches):\n",
    "    if not searches:\n",
    "        return {}\n",
    "    \n",
    "    searches = searches.split(\"-\")\n",
    "    fig = go.Figure(layout=go.Layout(\n",
    "        title = \"Docs containing searched words frequency\",\n",
    "        template=TEMPLATE,\n",
    "        xaxis=dict(\n",
    "            rangeselector=dict(\n",
    "                buttons=list([\n",
    "                    dict(count=1,\n",
    "                         label=\"1y\",\n",
    "                         step=\"year\",\n",
    "                         stepmode=\"backward\"),\n",
    "                    dict(count=5,\n",
    "                         label=\"5y\",\n",
    "                         step=\"year\",\n",
    "                         stepmode=\"backward\"),\n",
    "                    dict(count=10,\n",
    "                         label=\"10y\",\n",
    "                         step=\"year\",\n",
    "                         stepmode=\"backward\"),\n",
    "                    dict(count=25,\n",
    "                         label=\"25y\",\n",
    "                         step=\"year\",\n",
    "                         stepmode=\"backward\"),\n",
    "                    dict(count=50,\n",
    "                         label=\"50y\",\n",
    "                         step=\"year\",\n",
    "                         stepmode=\"backward\"),\n",
    "                    dict(step=\"all\")\n",
    "                ])\n",
    "            ),\n",
    "            rangeslider=dict(\n",
    "                visible=True\n",
    "            ),\n",
    "            title=\"year\",\n",
    "            type=\"date\"\n",
    "        ),\n",
    "        yaxis=dict(title=\"freq\")\n",
    "    ))\n",
    "    for search in searches:\n",
    "        search = search.strip()\n",
    "        grams = get_distribution(search, word2id, norm_dates, vectors_trans, dates_frequencies)\n",
    "        if not grams:\n",
    "            continue\n",
    "        fig.add_trace(go.Scatter(x=[year_perc[0] for year_perc in grams], y=[year_perc[1] for year_perc in grams],\n",
    "                            mode='lines',\n",
    "                            name=search))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "id": "71af87ec-70ea-4b9e-8869-849f7b1f7d0a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@app.callback(\n",
    "    Output(\"word-topics-graph\", \"figure\"),\n",
    "    [\n",
    "        Input('search-button', 'n_clicks'),\n",
    "        Input('word-topics-tabs', 'value')\n",
    "    ],\n",
    "    State('search-input', 'value'))\n",
    "def get_generic_topics_radar_graph(n_clicks, tab, searches):\n",
    "    if not searches:\n",
    "        return {}\n",
    "\n",
    "    fig = go.Figure(layout=go.Layout(\n",
    "            title=\"Topic distribution\",\n",
    "            template=TEMPLATE,\n",
    "    )               )\n",
    "    \n",
    "    searches = searches.split(\"-\")\n",
    "    for search in searches:\n",
    "        search = search.strip()\n",
    "        \n",
    "        topics = get_word_relevance(search, word2id, vocab, generic_lda_model if tab == \"Generic\" else specific_lda_model, normalize=True)\n",
    "        values = numpy.array(list(topics.values()), dtype='f') * 10 / max(topics.values())\n",
    "        \n",
    "        fig.add_trace(go.Scatterpolar(\n",
    "                  r=values,\n",
    "                  theta=[str(name) for name in list(topics.keys())],\n",
    "                  fill='toself',\n",
    "                  name=search\n",
    "            ))\n",
    "\n",
    "    fig.update_layout(\n",
    "      polar=dict(\n",
    "        radialaxis=dict(\n",
    "          visible=True,\n",
    "          range=[0, 10]\n",
    "        )),\n",
    "      showlegend=True\n",
    "    )\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "id": "62b3db48-80bc-4b34-b4d6-879a11f2c89e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@app.callback(\n",
    "    [\n",
    "        Output(\"topic-header\", \"children\"),\n",
    "        Output(\"topic-top-words-graph\", \"figure\"),\n",
    "        Output(\"topic-treemap\", \"figure\"),\n",
    "        Output(\"topic-wordcloud\", \"figure\")\n",
    "    ],\n",
    "    [\n",
    "        Input('word-topics-graph', 'clickData'),\n",
    "        Input('word-topics-tabs', 'value')\n",
    "    ],)\n",
    "def get_topic_words_radar_graph(selected_topic, tab):\n",
    "    if not selected_topic:\n",
    "        return [html.H5(\"Select a topic\")], {}, {}, {}\n",
    "    topic_id = selected_topic['points'][0]['pointNumber']\n",
    "    sim = get_topic_words(generic_lda_model if tab == \"Generic\" else specific_lda_model, \n",
    "                          topic_id,\n",
    "                          vectorizer, \n",
    "                          n_top_words=100, \n",
    "                          only_interesting=False)\n",
    "    \n",
    "    words = [word[0] for word in sim]\n",
    "    freqs = [word[1] for word in sim]\n",
    "    \n",
    "    treemap_trace = go.Treemap(\n",
    "        labels=words[:50], parents=[\"\"] * len(words[:50]), values=freqs\n",
    "    )\n",
    "    treemap_layout = go.Layout({\"margin\": dict(t=0, b=0, l=0, r=0, pad=0)})\n",
    "    treemap_figure = {\"data\": [treemap_trace], \"layout\": treemap_layout}\n",
    "    \n",
    "    wc = WordCloud().generate_from_frequencies(frequencies={word[0]: word[1] for word in sim})\n",
    "    wordcloud = get_wordcloud_graphs_topic_words(wc)\n",
    "    \n",
    "    return [html.H5(f\"{tab} Topic {topic_id}\")],px.histogram(\n",
    "        y=words[:20][::-1],\n",
    "        x=freqs[:20][::-1],\n",
    "        orientation=\"h\",     \n",
    "        color_discrete_sequence=['darkturquoise']\n",
    "    ).update_layout(\n",
    "        template=TEMPLATE,\n",
    "        xaxis_title='',\n",
    "        yaxis_title='',\n",
    "        height=550\n",
    "    ), treemap_figure, wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "id": "f8f58dd2-8fd8-4678-87fa-a7e1d3ac87b3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@app.callback(\n",
    "    Output(\"topic-years-histogram\", \"figure\"),\n",
    "    [\n",
    "        Input('word-topics-graph', 'clickData'),\n",
    "        Input('word-topics-tabs', 'value')\n",
    "    ],)\n",
    "def get_topic_words_radar_graph(selected_topic, tab):\n",
    "    if not selected_topic:\n",
    "        return {}\n",
    "    topic_id = selected_topic['points'][0]['pointNumber']\n",
    "    data = [\n",
    "        {\n",
    "            \"x\": list(topic_dists[topic_id].keys()),\n",
    "            \"y\": list(topic_dists[topic_id].values()),\n",
    "            \"text\": list(topic_dists[topic_id].keys()),\n",
    "            \"type\": \"bar\",\n",
    "            \"name\": \"\",\n",
    "        }\n",
    "    ]\n",
    "    layout = {\n",
    "        \"autosize\": True,\n",
    "        \"margin\": dict(t=10, b=20, l=40, r=0, pad=4),\n",
    "        \"xaxis\": dict(rangeselector=dict(\n",
    "            buttons=list([\n",
    "                dict(count=1,\n",
    "                     label=\"1y\",\n",
    "                     step=\"year\",\n",
    "                     stepmode=\"backward\"),\n",
    "                dict(count=5,\n",
    "                     label=\"5y\",\n",
    "                     step=\"year\",\n",
    "                     stepmode=\"backward\"),\n",
    "                dict(count=10,\n",
    "                     label=\"10y\",\n",
    "                     step=\"year\",\n",
    "                     stepmode=\"backward\"),\n",
    "                dict(count=25,\n",
    "                     label=\"25y\",\n",
    "                     step=\"year\",\n",
    "                     stepmode=\"backward\"),\n",
    "                dict(count=50,\n",
    "                     label=\"50y\",\n",
    "                     step=\"year\",\n",
    "                     stepmode=\"backward\"),\n",
    "                dict(step=\"all\")\n",
    "            ])\n",
    "        ),\n",
    "                       rangeslider=dict(\n",
    "                            visible=True\n",
    "                        ),\n",
    "                       title=\"year\",\n",
    "                       type=\"date\",\n",
    "                       showticklabels=True, )\n",
    "    }\n",
    "    return {\"data\": data, \"layout\": layout}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "id": "b2bb0f13-8ccc-4254-912c-559081773afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "app.layout = html.Div(children=[NAVBAR, BODY])\n",
    "\n",
    "app.run_server(mode='jupyterlab', dev_tools_ui=True, #debug=True, \n",
    "               dev_tools_hot_reload =True, threaded=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "911da111-c361-4398-869a-39e59c778834",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _terminate_server_for_port(host, port):\n",
    "        shutdown_url = \"http://{host}:{port}/_shutdown_{token}\".format(\n",
    "            host=host, port=port, token=JupyterDash._token\n",
    "        )\n",
    "        try:\n",
    "            response = requests.get(shutdown_url)\n",
    "        except Exception as e:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "5369e70b-ee4d-4d35-9ecd-e9b92b87091e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\carle\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning:\n",
      "\n",
      "Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# _terminate_server_for_port(\"localhost\", 8050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06185d4-9988-4d37-9257-b955de8f1f3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0142df49-aeb3-4da5-bb3e-2c9cc12273af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc5012d-1593-4b10-8fc8-92c262743302",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
