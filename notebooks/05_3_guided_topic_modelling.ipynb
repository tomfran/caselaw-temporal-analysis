{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from lda import guidedlda as glda\n",
    "\n",
    "from src.seeds import Seeds\n",
    "from src.vectorizers import TokenVectorizer\n",
    "from src.lda_utils import get_word_relevance, get_words_relevance, print_topics\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First five interesting: ['holdup', 'sulfate', 'smuggling', 'runaway', 'holstered']\n"
     ]
    }
   ],
   "source": [
    "seeds = Seeds()\n",
    "\n",
    "narcotics, weapons, investigation = seeds.get_final_filtered_seeds()\n",
    "\n",
    "interesting_set = narcotics.union(weapons).union(investigation)\n",
    "print(f\"First five interesting: {list(interesting_set)[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors, vectorizer = TokenVectorizer.load_vectors_vectorizer(method=\"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = vectorizer.get_feature_names()\n",
    "word2id = dict((v, idx) for idx, v in enumerate(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_numTopics = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_topic_list = [narcotics, investigation, weapons]\n",
    "seed_topics = {}\n",
    "\n",
    "for index in range(g_numTopics):\n",
    "    for i, st in enumerate(seed_topic_list):\n",
    "        for word in st:\n",
    "            if word in word2id:\n",
    "                seed_topics[word2id[word]] = 0\n",
    "            else:\n",
    "                print(f\"{word} not found in vocabulary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lda:n_documents: 123915\n",
      "INFO:lda:vocab_size: 48480\n",
      "INFO:lda:n_words: 89949046\n",
      "INFO:lda:n_topics: 14\n",
      "INFO:lda:n_iter: 100\n",
      "WARNING:lda:all zero row in document-term matrix found\n",
      "INFO:lda:<0> log likelihood: -965998649\n",
      "INFO:lda:<10> log likelihood: -824040779\n",
      "INFO:lda:<20> log likelihood: -760762122\n",
      "INFO:lda:<30> log likelihood: -751793045\n",
      "INFO:lda:<40> log likelihood: -749190151\n",
      "INFO:lda:<50> log likelihood: -748239937\n",
      "INFO:lda:<60> log likelihood: -747830939\n",
      "INFO:lda:<70> log likelihood: -747609779\n",
      "INFO:lda:<80> log likelihood: -747423694\n",
      "INFO:lda:<90> log likelihood: -747272555\n",
      "INFO:lda:<99> log likelihood: -747200636\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lda.guidedlda.GuidedLDA at 0x20e4adde670>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_alpha = 1/g_numTopics\n",
    "g_beta = 1/g_numTopics\n",
    "g_iter = 100\n",
    "\n",
    "glda_model = glda.GuidedLDA(n_topics=g_numTopics, \n",
    "                            n_iter=g_iter, \n",
    "                            random_state=0, \n",
    "                            refresh=10, \n",
    "                            alpha=g_alpha, \n",
    "                            eta=g_beta)\n",
    "\n",
    "glda_model.fit(vectors, \n",
    "               seed_topics=seed_topics, \n",
    "               seed_confidence=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(glda_model, open(\"../data/models/Guided_07_IAC_exp_seed_minf_10_max_50%.pk\", \"wb\"))\n",
    "# glda_model = pickle.load(open(\"../data/models/Guided_07_IAC_exp_seed_minf_10_max_50%.pk\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guided lda topics\n",
      "\n",
      "Topic: 0\n",
      "0.01*people + 0.01*testify + 0.01*officer + 0.01*police + 0.01*testimony + 0.01*jury + 0.01*witness + 0.01*statement + 0.01*tell + 0.01*defense\n",
      "\n",
      "Topic: 1\n",
      "0.03*appellant + 0.02*appellee + 0.01*plaintiff + 0.01*error + 0.01*pay + 0.01*bill + 0.01*suit + 0.01*jury + 0.01*claim + 0.01*contract\n",
      "\n",
      "Topic: 2\n",
      "0.03*contract + 0.02*plaintiff + 0.02*agreement + 0.01*lease + 0.01*sale + 0.01*business + 0.01*purchase + 0.01*term + 0.01*work + 0.01*pay\n",
      "\n",
      "Topic: 3\n",
      "0.02*petitioner + 0.02*fee + 0.02*award + 0.01*pay + 0.01*support + 0.01*attorney + 0.01*claimant + 0.01*marriage + 0.01*child + 0.01*respondent\n",
      "\n",
      "Topic: 4\n",
      "0.02*board + 0.01*illinois + 0.01*section + 0.01*department + 0.01*employee + 0.01*decision + 0.01*review + 0.01*public + 0.01*commission + 0.01*school\n",
      "\n",
      "Topic: 5\n",
      "0.02*child + 0.02*respondent + 0.01*testify + 0.01*medical + 0.01*hospital + 0.01*parent + 0.01*mother + 0.01*care + 0.01*minor + 0.01*father\n",
      "\n",
      "Topic: 6\n",
      "0.03*city + 0.02*county + 0.02*section + 0.01*statute + 0.01*ordinance + 0.01*district + 0.01*tax + 0.01*shall + 0.01*petition + 0.01*board\n",
      "\n",
      "Topic: 7\n",
      "0.06*plaintiff + 0.02*motion + 0.02*complaint + 0.01*allege + 0.01*dismiss + 0.01*claim + 0.01*count + 0.01*section + 0.01*rule + 0.01*amend\n",
      "\n",
      "Topic: 8\n",
      "0.04*policy + 0.04*insurance + 0.02*insure + 0.01*liability + 0.01*coverage + 0.01*company + 0.01*claim + 0.01*plaintiff + 0.01*injury + 0.01*loss\n",
      "\n",
      "Topic: 9\n",
      "0.02*sentence + 0.01*people + 0.01*counsel + 0.01*motion + 0.01*petition + 0.01*hearing + 0.01*charge + 0.01*section + 0.01*judge + 0.01*rule\n",
      "\n",
      "Topic: 10\n",
      "0.04*property + 0.02*use + 0.02*land + 0.02*estate + 0.01*lot + 0.01*plaintiff + 0.01*owner + 0.01*building + 0.01*value + 0.01*real\n",
      "\n",
      "Topic: 11\n",
      "0.01*plaintiff + 0.01*car + 0.01*appellant + 0.01*work + 0.01*appellee + 0.01*street + 0.01*injury + 0.01*negligence + 0.01*jury + 0.01*track\n",
      "\n",
      "Topic: 12\n",
      "0.04*plaintiff + 0.02*jury + 0.01*verdict + 0.01*testify + 0.01*injury + 0.01*accident + 0.01*vehicle + 0.01*car + 0.01*testimony + 0.01*instruction\n",
      "\n",
      "Topic: 13\n",
      "0.02*bank + 0.01*trust + 0.01*interest + 0.01*note + 0.01*decree + 0.01*pay + 0.01*company + 0.01*corporation + 0.01*mortgage + 0.01*payment\n",
      "\n",
      "Topics with only interesting words\n",
      "\n",
      "Topic: 0\n",
      "0.01*arrest + 0.0*murder + 0.0*gun + 0.0*robbery + 0.0*warrant + 0.0*detective + 0.0*armed + 0.0*weapon + 0.0*drug + 0.0*fire\n",
      "\n",
      "Topic: 1\n",
      "0.0*warrant + 0.0*fraud + 0.0*discharge + 0.0*substance + 0.0*death + 0.0*die + 0.0*thompson + 0.0*arrest + 0.0*don + 0.0*scam\n",
      "\n",
      "Topic: 2\n",
      "0.0*fraud + 0.0*violation + 0.0*plant + 0.0*warrant + 0.0*chemical + 0.0*pipe + 0.0*cal + 0.0*green + 0.0*don + 0.0*substance\n",
      "\n",
      "Topic: 3\n",
      "0.0*abuse + 0.0*medical + 0.0*death + 0.0*warrant + 0.0*green + 0.0*die + 0.0*discharge + 0.0*cal + 0.0*alia + 0.0*don\n",
      "\n",
      "Topic: 4\n",
      "0.0*discharge + 0.0*violation + 0.0*fire + 0.0*plant + 0.0*substance + 0.0*possess + 0.0*chemical + 0.0*medical + 0.0*cal + 0.0*sex\n",
      "\n",
      "Topic: 5\n",
      "0.01*medical + 0.0*abuse + 0.0*sexual + 0.0*death + 0.0*blood + 0.0*drug + 0.0*sexually + 0.0*die + 0.0*sex + 0.0*discharge\n",
      "\n",
      "Topic: 6\n",
      "0.0*violation + 0.0*fire + 0.0*prescribe + 0.0*warrant + 0.0*possess + 0.0*substance + 0.0*thompson + 0.0*green + 0.0*alia + 0.0*prostitution\n",
      "\n",
      "Topic: 7\n",
      "0.0*fraud + 0.0*abuse + 0.0*violation + 0.0*medical + 0.0*concealment + 0.0*warrant + 0.0*alia + 0.0*cal + 0.0*substance + 0.0*discharge\n",
      "\n",
      "Topic: 8\n",
      "0.0*fire + 0.0*death + 0.0*medical + 0.0*cal + 0.0*die + 0.0*violation + 0.0*kill + 0.0*discharge + 0.0*theft + 0.0*chemical\n",
      "\n",
      "Topic: 9\n",
      "0.0*violation + 0.0*abuse + 0.0*arrest + 0.0*burglary + 0.0*murder + 0.0*theft + 0.0*aggravate + 0.0*armed + 0.0*discharge + 0.0*robbery\n",
      "\n",
      "Topic: 10\n",
      "0.0*death + 0.0*die + 0.0*plant + 0.0*green + 0.0*possess + 0.0*prescription + 0.0*thompson + 0.0*abuse + 0.0*pipe + 0.0*violation\n",
      "\n",
      "Topic: 11\n",
      "0.0*fire + 0.0*pipe + 0.0*death + 0.0*kill + 0.0*plant + 0.0*violation + 0.0*crew + 0.0*warrant + 0.0*substance + 0.0*discharge\n",
      "\n",
      "Topic: 12\n",
      "0.0*intoxication + 0.0*blood + 0.0*death + 0.0*violation + 0.0*green + 0.0*abuse + 0.0*medical + 0.0*fire + 0.0*don + 0.0*chemical\n",
      "\n",
      "Topic: 13\n",
      "0.0*fraud + 0.0*discharge + 0.0*death + 0.0*die + 0.0*warrant + 0.0*substance + 0.0*forgery + 0.0*possess + 0.0*thompson + 0.0*gage\n"
     ]
    }
   ],
   "source": [
    "print(\"Guided lda topics\")\n",
    "print_topics(glda_model, \n",
    "             vectorizer, \n",
    "             n_top_words=10, \n",
    "             only_interesting=False)\n",
    "\n",
    "print(\"\\nTopics with only interesting words\")\n",
    "print_topics(glda_model, \n",
    "             vectorizer, \n",
    "             n_top_words=10, \n",
    "             only_interesting=True, \n",
    "             interesting_set=interesting_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
