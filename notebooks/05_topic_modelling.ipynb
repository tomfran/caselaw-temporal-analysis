{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic modelling\n",
    "\n",
    "The goal is to find three topics from the collection, the firt one regarding drugs, the second weapons, and the third investigation. \n",
    "\n",
    "We start with a classic model to then test the guided lda approach. We do not expect the first one to find the three topics we want, while the second should guide the topic modelling towards the required goal.\n",
    "\n",
    "References:\n",
    "https://medium.com/analytics-vidhya/how-i-tackled-a-real-world-problem-with-guidedlda-55ee803a6f0d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.decomposition import LatentDirichletAllocation as lda\n",
    "from lda import guidedlda as glda\n",
    "\n",
    "# import pyLDAvis.sklearn\n",
    "# pyLDAvis.enable_notebook()\n",
    "\n",
    "from src.dataset import Dataset\n",
    "from src.vectorizers import TokenVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset()\n",
    "# load only the year specified\n",
    "# year = None # carica tutto\n",
    "year = None # carico solo quel ventennio \n",
    "\n",
    "tokens = dataset.load_dataset(year=year, tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtra i dati, se vuoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = defaultdict(lambda:0)\n",
    "for doc in tokens:\n",
    "    for w in doc:\n",
    "    # for w in set(doc):        \n",
    "        freq[w] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "narcotics = ['cannabis', 'cocaine', 'methamphetamine', 'drugs', 'drug', 'marijuana', \n",
    "             'ecstasy', 'lsd', 'ketamine', 'heroin', 'fentanyl', 'overdose']\n",
    "\n",
    "weapons = ['gun', 'knife', 'weapon', 'firearm', 'rifle', 'carabine', 'shotgun', 'handgun', \n",
    "           'revolver', 'musket', 'pistol', 'derringer', 'assault', 'rifle', 'sword', 'blunt']\n",
    "\n",
    "investigation = ['gang', 'mafia', 'serial',  'killer', 'rape', 'theft', 'recidivism', \n",
    "                 'arrest', 'robbery', 'cybercrime', 'cyber', 'crime']\n",
    "\n",
    "interesting_set = set(narcotics + weapons + investigation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sel_criterium(w):\n",
    "    return (w in interesting_set) or (len(w) >= 3) and (10 < freq[w] < 0.5*len(tokens))\n",
    "\n",
    "tokens = [[w for w in doc if sel_criterium(w)] for doc in tokens]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize the documents\n",
    "The vectorized is a tfidf one, we use the output to fit the lda model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary length: 89943\n"
     ]
    }
   ],
   "source": [
    "dv = TokenVectorizer(tokens, method=\"count\")\n",
    "\n",
    "vectors = dv.vectors()\n",
    "dv.save_vectors_vectorizer(vectors)\n",
    "print(f\"Vocabulary length: {len(dv.vectorizer.vocabulary_)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading precomputed vectors, this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors, vectorizer = TokenVectorizer.load_vectors_vectorizer(method=\"count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classic LDA model\n",
    "\n",
    "The number of topics is set to three, while alpha and beta have values proposed in the literature. \n",
    "\n",
    "Griffiths TL, Steyvers M (2004). “Finding Scientific Topics.” Proceedings of the National Academy of Sciences of the United States of America, 101, 5228–5235."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "numTopics = 10\n",
    "# alpha = 50/numTopics\n",
    "alpha = 0.1\n",
    "beta = 0.01\n",
    "\n",
    "lda_model = lda(n_components = numTopics, \n",
    "                doc_topic_prior= alpha, \n",
    "                topic_word_prior = beta, \n",
    "                random_state=0, \n",
    "                n_jobs=-1)\n",
    "\n",
    "lda_output = lda_model.fit_transform(vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topics relevant words\n",
    "\n",
    "The next step is to check the words for each topic, results are interesting and expected, bu twe can't see a distinction between the topics we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic: 0\n",
      "constitution, election, legislature, member, article, injunction, license, amendment, constitutional, vote\n",
      "\n",
      "Topic: 1\n",
      "crime, arrest, prosecutor, indictment, convict, sexual, abuse, sentencing, prosecution, juror\n",
      "\n",
      "Topic: 2\n",
      "lease, price, rate, loss, contractor, agent, rent, furnish, perform, market\n",
      "\n",
      "Topic: 3\n",
      "village, assessment, road, water, town, levy, railroad, improvement, line, commissioner\n",
      "\n",
      "Topic: 4\n",
      "track, train, railroad, injure, automobile, drive, truck, safety, declaration, side\n",
      "\n",
      "Topic: 5\n",
      "marriage, search, custody, parent, divorce, warrant, husband, father, income, marital\n",
      "\n",
      "Topic: 6\n",
      "hospital, medical, expert, test, physician, industrial, compensation, doctor, treatment, decedent\n",
      "\n",
      "Topic: 7\n",
      "door, room, gun, arrest, apartment, stop, fire, store, floor, walk\n",
      "\n",
      "Topic: 8\n",
      "trustee, execute, stock, lien, execution, equity, debt, certificate, creditor, mrs\n",
      "\n",
      "Topic: 9\n",
      "summary, dismissal, assert, limitation, allegation, civil, employer, insure, procedure, affidavit\n"
     ]
    }
   ],
   "source": [
    "n_top_words = 10\n",
    "\n",
    "vocab = vectorizer.get_feature_names()\n",
    "topic_words = {}\n",
    "for topic, comp in enumerate(lda_model.components_): \n",
    "    word_idx = np.argsort(comp)[::-1][:n_top_words]\n",
    "    topic_words[topic] = [vocab[i] for i in word_idx]\n",
    "    \n",
    "for topic, words in topic_words.items():\n",
    "    print('\\nTopic: %d' % topic)\n",
    "    print('%s' % ', '.join(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consider only words of interest\n",
    "We now print the word distribution, considering only interesting words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic: 0\n",
      "crime, arrest, drug, theft, firearm, assault, serial, cannabis, weapon, drugs\n",
      "\n",
      "Topic: 1\n",
      "crime, arrest, robbery, assault, drug, theft, gun, rape, weapon, gang\n",
      "\n",
      "Topic: 2\n",
      "serial, theft, sword, drugs, drug, arrest, blunt, killer, crime, firearm\n",
      "\n",
      "Topic: 3\n",
      "arrest, sword, fentanyl, crime, blunt, assault, gang, drug, rifle, firearm\n",
      "\n",
      "Topic: 4\n",
      "gang, arrest, assault, serial, theft, knife, killer, shotgun, drug, drugs\n",
      "\n",
      "Topic: 5\n",
      "arrest, cocaine, drug, cannabis, marijuana, heroin, methamphetamine, lsd, weapon, serial\n",
      "\n",
      "Topic: 6\n",
      "drug, arrest, overdose, blunt, marijuana, cannabis, cocaine, killer, methamphetamine, assault\n",
      "\n",
      "Topic: 7\n",
      "gun, arrest, crime, weapon, robbery, knife, assault, revolver, pistol, shotgun\n",
      "\n",
      "Topic: 8\n",
      "arrest, sword, blunt, serial, assault, drug, crime, theft, rifle, cyber\n",
      "\n",
      "Topic: 9\n",
      "drug, theft, sword, drugs, assault, blunt, crime, serial, arrest, firearm\n"
     ]
    }
   ],
   "source": [
    "topic_words = {}\n",
    "for topic, comp in enumerate(lda_model.components_): \n",
    "    word_idx = np.argsort(comp)[::-1]\n",
    "    topic_words[topic] = [w for w in [vocab[i] for i in word_idx] if w in interesting_set][:n_top_words]\n",
    "    \n",
    "for topic, words in topic_words.items():\n",
    "    print('\\nTopic: %d' % topic)\n",
    "    print('%s' % ', '.join(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the topics blends together even considering only the words of interest, LDA must be guided. \n",
    "\n",
    "## Guided LDA approach\n",
    "We now guide the lda process by setting some seeds, exploiting the model defined by the GuidedLDA package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2id = dict((v, idx) for idx, v in enumerate(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cybercrime not found in vocabulary\n",
      "carabine not found in vocabulary\n"
     ]
    }
   ],
   "source": [
    "seed_topic_list = [narcotics, investigation, weapons]\n",
    "seed_topics = {}\n",
    "\n",
    "for i, st in enumerate(seed_topic_list):\n",
    "    for word in st:\n",
    "        if word in word2id:\n",
    "            seed_topics[word2id[word]] = i\n",
    "        else:\n",
    "            print(f\"{word} not found in vocabulary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lda:n_documents: 183146\n",
      "INFO:lda:vocab_size: 89943\n",
      "INFO:lda:n_words: 79362124\n",
      "INFO:lda:n_topics: 10\n",
      "INFO:lda:n_iter: 250\n",
      "WARNING:lda:all zero row in document-term matrix found\n",
      "INFO:lda:<0> log likelihood: -879179572\n",
      "INFO:lda:<10> log likelihood: -746208315\n",
      "INFO:lda:<20> log likelihood: -709967559\n",
      "INFO:lda:<30> log likelihood: -705226937\n",
      "INFO:lda:<40> log likelihood: -703361333\n",
      "INFO:lda:<50> log likelihood: -702222837\n",
      "INFO:lda:<60> log likelihood: -701393400\n",
      "INFO:lda:<70> log likelihood: -700808215\n",
      "INFO:lda:<80> log likelihood: -700356755\n",
      "INFO:lda:<90> log likelihood: -699991570\n",
      "INFO:lda:<100> log likelihood: -699691969\n",
      "INFO:lda:<110> log likelihood: -699408386\n",
      "INFO:lda:<120> log likelihood: -699129151\n",
      "INFO:lda:<130> log likelihood: -698936185\n",
      "INFO:lda:<140> log likelihood: -698809886\n",
      "INFO:lda:<150> log likelihood: -698678869\n",
      "INFO:lda:<160> log likelihood: -698547644\n",
      "INFO:lda:<170> log likelihood: -698483851\n",
      "INFO:lda:<180> log likelihood: -698380867\n",
      "INFO:lda:<190> log likelihood: -698318069\n",
      "INFO:lda:<200> log likelihood: -698239159\n",
      "INFO:lda:<210> log likelihood: -698177017\n",
      "INFO:lda:<220> log likelihood: -698104951\n",
      "INFO:lda:<230> log likelihood: -698025759\n",
      "INFO:lda:<240> log likelihood: -697953892\n",
      "INFO:lda:<249> log likelihood: -697906924\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lda.guidedlda.GuidedLDA at 0x278521bbfa0>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glda_model = glda.GuidedLDA(n_topics=10, \n",
    "                       n_iter=250, \n",
    "                       random_state=0, \n",
    "                       refresh=10, \n",
    "                       alpha=alpha, \n",
    "                       eta=beta)\n",
    "\n",
    "glda_model.fit(vectors, \n",
    "          seed_topics=seed_topics, \n",
    "          seed_confidence=0.90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "medical hospital parent minor expert treatment physician mental doctor mother custody patient father health abuse disability test suffer physical week\n",
      "drug assault overdose blunt arrest marijuana cocaine recidivism killer sword\n",
      "Topic 1:\n",
      "arrest crime search doubt gun robbery convict apartment indictment prosecutor identify juror sentencing warrant prosecution armed door felony drive guilt\n",
      "arrest crime gun robbery assault drug weapon theft rape cocaine\n",
      "Topic 2:\n",
      "train track drive truck injure stop fall side railroad driver automobile industrial run safety passenger light strike operate danger hour\n",
      "gang arrest knife assault gun rifle serial killer firearm fentanyl\n",
      "Topic 3:\n",
      "vacate affidavit final dismissal marriage civil serve relief merit post procedure represent limitation arbitration allegation october december statutory november august\n",
      "sword arrest weapon drugs fentanyl firearm handgun gun gang heroin\n",
      "Topic 4:\n",
      "assessment election taxis levy constitution legislature commissioner certificate authorize town vote clerk article member director compensation rate assess writ municipal\n",
      "crime arrest fentanyl firearm heroin gang gun handgun blunt cannabis\n",
      "Topic 5:\n",
      "administrative agency federal employment class legislature member regulation standard united employer process protection violate statutory requirement states union individual immunity\n",
      "drug crime drugs firearm blunt sword serial weapon theft cyber\n",
      "Topic 6:\n",
      "lease insure summary breach coverage loss contractor loan insurer lien letter fraud national agent limit settlement rent corp mutual obligation\n",
      "theft serial drug drugs sword blunt gang heroin assault handgun\n",
      "Topic 7:\n",
      "trustee husband mrs share testator life convey heir execute die probate executor equity john son conveyance father live administrator lien\n",
      "assault rifle firearm fentanyl gang gun heroin handgun blunt cannabis\n",
      "Topic 8:\n",
      "water village road line railroad north improvement area south park highway east construct zone tract acre propose bridge build locate\n",
      "firearm fentanyl handgun gun heroin gang blunt cannabis arrest assault\n",
      "Topic 9:\n",
      "agent declaration execution stock check price writ demand true assign affidavit transaction exception execute bind thereof creditor seem sue letter\n",
      "arrest sword blunt serial assault theft firearm fentanyl heroin handgun\n"
     ]
    }
   ],
   "source": [
    "topic_word = glda_model.topic_word_\n",
    "for i, topic_dist in enumerate(topic_word):\n",
    "    topic_words = np.array(vocab)[np.argsort(topic_dist)][::-1]\n",
    "    interesting_topic_words = [w for w in topic_words if w in interesting_set][:n_top_words]\n",
    "    print(f\"Topic {i}:\\n{' '.join(topic_words[:n_top_words * 2])}\\n{' '.join(interesting_topic_words)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_dictionary, common_corpus\n",
    "from gensim.models import LsiModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_vocabulary = { dv.vectorizer.vocabulary_[k]:k for k in dv.vectorizer.vocabulary_}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.lsimodel:using serial LSI version on this node\n",
      "INFO:gensim.models.lsimodel:updating model with new documents\n",
      "INFO:gensim.models.lsimodel:using 100 extra samples and 2 power iterations\n",
      "INFO:gensim.models.lsimodel:1st phase: constructing (89943, 110) action matrix\n",
      "INFO:gensim.models.lsimodel:orthonormalizing (89943, 110) action matrix\n",
      "INFO:gensim.models.lsimodel:2nd phase: running dense svd on (110, 183146) matrix\n",
      "INFO:gensim.models.lsimodel:computing the final decomposition\n",
      "INFO:gensim.models.lsimodel:keeping 10 factors (discarding 63.532% of energy spectrum)\n",
      "INFO:gensim.models.lsimodel:processed sparse job of 183146 documents\n",
      "INFO:gensim.utils:LsiModel lifecycle event {'msg': 'trained LsiModel(num_terms=89943, num_topics=10, decay=1.0, chunksize=20000) in 63.97s', 'datetime': '2021-11-25T03:35:53.454214', 'gensim': '4.1.2', 'python': '3.9.1 (tags/v3.9.1:1e5d33e, Dec  7 2020, 17:08:21) [MSC v.1927 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "model = LsiModel(vectors.transpose(), id2word=reverse_vocabulary, num_topics=numTopics) \n",
    "topics = model.get_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0\n",
      "[('arrest', 0.09), ('crime', 0.08), ('standard', 0.07), ('united', 0.07), ('member', 0.07), ('test', 0.07), ('amendment', 0.07), ('factor', 0.07), ('abuse', 0.07), ('hospital', 0.06)] \n",
      "\n",
      "Topic 1\n",
      "[('arrest', -0.23), ('crime', -0.18), ('stock', 0.14), ('search', -0.14), ('trustee', 0.13), ('prosecutor', -0.12), ('gun', -0.12), ('lease', 0.11), ('apartment', -0.11), ('robbery', -0.1)] \n",
      "\n",
      "Topic 2\n",
      "[('railroad', 0.26), ('track', 0.19), ('medical', -0.18), ('hospital', -0.16), ('road', 0.16), ('train', 0.15), ('line', 0.14), ('north', 0.14), ('south', 0.13), ('east', 0.12)] \n",
      "\n",
      "Topic 3\n",
      "[('stock', -0.25), ('trustee', -0.18), ('railroad', 0.17), ('share', -0.17), ('village', 0.16), ('road', 0.13), ('track', 0.13), ('mrs', -0.12), ('train', 0.11), ('marriage', -0.11)] \n",
      "\n",
      "Topic 4\n",
      "[('election', -0.36), ('constitution', -0.23), ('vote', -0.21), ('ballot', -0.2), ('hospital', 0.16), ('medical', 0.15), ('legislature', -0.13), ('search', -0.13), ('constitutional', -0.12), ('amendment', -0.12)] \n",
      "\n",
      "Topic 5\n",
      "[('search', -0.23), ('election', 0.22), ('parent', 0.21), ('coverage', -0.2), ('arrest', -0.18), ('lease', -0.17), ('mother', 0.17), ('custody', 0.17), ('insure', -0.17), ('father', 0.15)] \n",
      "\n",
      "Topic 6\n",
      "[('search', -0.31), ('election', 0.3), ('ballot', 0.23), ('custody', -0.2), ('parent', -0.2), ('arrest', -0.19), ('warrant', -0.17), ('vote', 0.16), ('marriage', -0.15), ('minor', -0.13)] \n",
      "\n",
      "Topic 7\n",
      "[('hospital', -0.3), ('search', -0.27), ('stock', -0.27), ('lease', 0.23), ('medical', -0.23), ('arrest', -0.19), ('patient', -0.15), ('coverage', 0.15), ('warrant', -0.14), ('physician', -0.14)] \n",
      "\n",
      "Topic 8\n",
      "[('election', -0.33), ('stock', 0.28), ('ballot', -0.25), ('coverage', -0.24), ('insure', -0.2), ('search', -0.19), ('lease', -0.16), ('vote', -0.14), ('arrest', -0.13), ('share', 0.13)] \n",
      "\n",
      "Topic 9\n",
      "[('lease', 0.57), ('coverage', -0.27), ('stock', -0.21), ('insure', -0.21), ('hospital', 0.17), ('rent', 0.15), ('insurer', -0.13), ('tenant', 0.12), ('railroad', -0.12), ('share', -0.11)] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "topWords = []\n",
    "for topicno in range(numTopics):\n",
    "    print('Topic {}'.format(topicno))\n",
    "    print([(x, round(y, 2)) for x, y in model.show_topic(topicno, topn=10)], '\\n')\n",
    "    topWords.append([(x) for x, y in model.show_topic(topicno, topn=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
